<!doctype html><html lang=en-gb><title>On mindcrime | George Thomas</title><meta charset=utf-8><meta name=generator content="Hugo 0.111.3"><meta name=viewport content="width=device-width,initial-scale=1"><link rel=stylesheet href=https://geotho.github.io/css/index.css><link rel=stylesheet href=https://geotho.github.io/css/classes.css><link rel=canonical href=https://geotho.github.io/post/2017/2017-01-16-on-mindcrime/><link rel=alternate type=application/rss+xml href title="George Thomas"><link rel=icon type=image/svg+xml href=/favicon.svg><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css integrity=sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js integrity=sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-DXK82H4CPF"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-DXK82H4CPF",{anonymize_ip:!1})}</script><body><header class=icons><a href=https://geotho.github.io/>George Thomas</a><nav><a href=/about/>About</a>
<a href=/projects/>Projects</a></nav></header><article><header><h1>On mindcrime</h1><time datetime=2017-01-16T00:00:00Z>January 16, 2017</time></header><p>One of the interesting ideas in Bostrom’s <em>Superintelligence</em> (a book not short on interesting ideas) is that of mindcrime.</p><p>Suppose a superintelligence could simulate human beings in order to learn more about their psychology. The crime arises when these simulations lead to cruel experiments which cause the simulated human beings harm. Because a superintelligence is likely to be made of electronics rather than old-fashioned biology, the harm can be caused at light-speed, far more efficiently than any harm humans could directly cause.</p><p>A good book raises more questions than it answers. I’ve been thinking about the following questions and possible answers ever since:</p><p><strong>How could humans be simulated at all?</strong></p><p>Discussed in the book is the idea of <a href=https://en.wikipedia.org/wiki/Mind_uploading>whole brain emulation</a> as one possible avenue of simulation. One could slice, scan and map the brain and then emulate its operation inside a computer. The emulation should, if correct, behave as though the brain were still operational.</p><p><strong>How could simulated human feel pain if they are only simulated?</strong></p><p>This seems to be the <a href=https://en.wikipedia.org/wiki/Problem_of_other_minds>problem of other minds</a>. How can you know anyone else feels pain? Perhaps they are all faking. Bostrom also argues that it is likely that we are already <a href=http://www.simulation-argument.com/>living in a simulation</a>. So to find a simulated human who feels pain, you might only have to look to yourself. But certainly if the humans were simulated with whole brain emulation, I see no reason why they wouldn’t be able to feel pain.</p><p><strong>I can imagine people in pain. How do I know I am not committing mind crime?</strong></p><p>It seems unlikely to me that my imaginations are capable of subjective experience. Partly because it seems impossible for my brain to simulate the entirety of another brain and also because imaginings don’t tend to behave of their own accord.</p><hr><p>I&rsquo;m still reeling from the book, and recommend it to anyone wanting to learn more about the inherent danger in what is potentially humanity&rsquo;s last invention.</p></article></body></html>